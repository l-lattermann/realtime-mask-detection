{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML files from train runs\n",
    "v8_mask = \"train_runs/yolov8n_mask_100epochs/train/args.yaml\"\n",
    "v8_person = \"train_runs/yolov8n_person_100epochs/detect/train/args.yaml\"\n",
    "v11_mask =  \"train_runs/yolo11n_mask_100epochs/train/args.yaml\"\n",
    "v11_person = \"train_runs/yolo11n_person_100epochs/train/args.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML files\n",
    "files = [v8_mask, v8_person, v11_mask, v11_person]\n",
    "yaml_data = {file: yaml.safe_load(open(file)) for file in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_runs/yolov8n_mask_100epochs/train/args.yaml', 'train_runs/yolov8n_person_100epochs/detect/train/args.yaml', 'train_runs/yolo11n_mask_100epochs/train/args.yaml', 'train_runs/yolo11n_person_100epochs/train/args.yaml'])\n",
      "dict_keys(['task', 'mode', 'model', 'data', 'epochs', 'time', 'patience', 'batch', 'imgsz', 'save', 'save_period', 'cache', 'device', 'workers', 'project', 'name', 'exist_ok', 'pretrained', 'optimizer', 'verbose', 'seed', 'deterministic', 'single_cls', 'rect', 'cos_lr', 'close_mosaic', 'resume', 'amp', 'fraction', 'profile', 'freeze', 'multi_scale', 'overlap_mask', 'mask_ratio', 'dropout', 'val', 'split', 'save_json', 'save_hybrid', 'conf', 'iou', 'max_det', 'half', 'dnn', 'plots', 'source', 'vid_stride', 'stream_buffer', 'visualize', 'augment', 'agnostic_nms', 'classes', 'retina_masks', 'embed', 'show', 'save_frames', 'save_txt', 'save_conf', 'save_crop', 'show_labels', 'show_conf', 'show_boxes', 'line_width', 'format', 'keras', 'optimize', 'int8', 'dynamic', 'simplify', 'opset', 'workspace', 'nms', 'lr0', 'lrf', 'momentum', 'weight_decay', 'warmup_epochs', 'warmup_momentum', 'warmup_bias_lr', 'box', 'cls', 'dfl', 'pose', 'kobj', 'nbs', 'hsv_h', 'hsv_s', 'hsv_v', 'degrees', 'translate', 'scale', 'shear', 'perspective', 'flipud', 'fliplr', 'bgr', 'mosaic', 'mixup', 'copy_paste', 'copy_paste_mode', 'auto_augment', 'erasing', 'crop_fraction', 'cfg', 'tracker', 'save_dir'])\n",
      "dict_values(['detect', 'train', 'yolo11n.yaml', '/content/Real-time-Face-Mask-Detection-and-Validation-System-Dataset-4/data.yaml', 100, None, 100, 16, 640, True, -1, False, 0, 8, None, 'train', False, 'yolo11n.pt', 'auto', True, 0, True, False, False, False, 10, False, True, 1.0, False, None, False, True, 4, 0.0, True, 'val', False, False, None, 0.7, 300, False, False, True, None, 1, False, False, False, False, None, False, None, False, False, False, False, False, True, True, True, None, 'torchscript', False, False, False, False, True, None, None, False, 0.01, 0.01, 0.937, 0.0005, 3.0, 0.8, 0.1, 7.5, 0.5, 1.5, 12.0, 1.0, 64, 0.015, 0.7, 0.4, 0.0, 0.1, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 'flip', 'randaugment', 0.4, 1.0, None, 'botsort.yaml', 'runs/detect/train'])\n",
      "Values for model are not equal: yolo11n.yaml, yolov8n.yaml, yolo11n.yaml, yolo11n.yaml\n",
      "Values for data are not equal: /content/Real-time-Face-Mask-Detection-and-Validation-System-Dataset-4/data.yaml, /content/Person-detection-16/data.yaml, /content/Real-time-Face-Mask-Detection-and-Validation-System-Dataset-4/data.yaml, /content/Person-detection-16/data.yaml\n",
      "Values for pretrained are not equal: yolo11n.pt, yolov8n.pt, yolo11n.pt, yolo11n.pt\n"
     ]
    }
   ],
   "source": [
    "print(yaml_data.keys())\n",
    "print(yaml_data[v8_mask].keys())\n",
    "print(yaml_data[v8_mask].values())\n",
    "\n",
    "# Check if all values are equal\n",
    "for key in yaml_data[v8_mask].keys():\n",
    "    if yaml_data[v8_mask][key]  == yaml_data[v8_person][key] == yaml_data[v11_mask][key] == yaml_data[v11_person][key]:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Values for {key} are not equal: {yaml_data[v8_mask][key]}, {yaml_data[v8_person][key]}, {yaml_data[v11_mask][key]}, {yaml_data[v11_person][key]}\")\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "params_df = pd.DataFrame({\n",
    "    \"parameters\": list(yaml_data[v8_mask].keys()),  # Get parameter names from one file\n",
    "    \"v8_mask\": yaml_data[v8_mask].values(),\n",
    "    \"v8_person\": yaml_data[v8_person].values(),\n",
    "    \"v11_mask\": yaml_data[v11_mask].values(),\n",
    "    \"v11_person\": yaml_data[v11_person].values()\n",
    "})\n",
    "\n",
    "params_df.to_csv(\"train_runs/train_arg_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
