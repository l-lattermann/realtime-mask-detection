{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import psutil\n",
    "import sys\n",
    "import threading\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "v8n_person = YOLO(\"train_runs/yolov8n_person_100epochs/detect/train/weights/best.pt\")\n",
    "v8n_mask = YOLO(\"train_runs/yolov8n_mask_100epochs/train/weights/best.pt\")\n",
    "v11n_person = YOLO(\"train_runs/yolo11n_person_100epochs/train/weights/best.pt\")\n",
    "v11n_mask = YOLO(\"train_runs/yolo11n_mask_100epochs/train/weights/best.pt\")\n",
    "\n",
    "# Create model list\n",
    "model_dict = {\"v8n_person\":v8n_person, \"v8n_mask\":v8n_mask, \"v11n_person\":v11n_person, \"v11n_mask\":v11n_mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if model was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot result images\n",
    "def matplot_image(results: list, model_name: str):\n",
    "    \"\"\"\n",
    "        Display the image using matplotlib\n",
    "        :param results: list of results from the model\n",
    "        :param model_name: name of the model\n",
    "    \"\"\"\n",
    "\n",
    "    im  = results[0].plot()\n",
    "    # Convert BGR (OpenCV format) to RGB (matplotlib format)\n",
    "    im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Add model name to the image\n",
    "    plt.title(model_name)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.axis(\"off\")  # Turn off axes for a cleaner display\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set confidence and IOU threshold\n",
    "conf = 0.3\n",
    "iou = 0.3\n",
    "\n",
    "# Test models\n",
    "for model_name, model in model_dict.items():\n",
    "    for i in range(3):\n",
    "        results = model.predict(f\"data_sets/image_data/mask_person_test/{i}.jpg\", conf=conf, iou=iou, verbose=False)\n",
    "\n",
    "        # Show results\n",
    "        #matplot_image(results, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RAM usage\n",
    "def get_ram_usage():\n",
    "    \"\"\"\n",
    "        Get the RAM usage of the system\n",
    "        :return: RAM usage in MB\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get current process\n",
    "    process = psutil.Process()\n",
    "\n",
    "    # Get memory usage in bytes and convert to MB\n",
    "    return process.memory_info().rss / (1024 ** 2)  # Resident Set Size (RSS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put stats bar on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put stats bar on frame\n",
    "def put_stats_bar(frame, t0_inf=0, t1_inf=0, t0_ann=0, t1_ann=0, loop_time=0, bar_height=30,font_scale=0.5, font_thickness=1):\n",
    "    \"\"\"\n",
    "        Add a stats bar at the bottom of the frame\n",
    "        :param frame: frame to add the stats bar to\n",
    "        :param t0_inf: start time of inference\n",
    "        :param t1_inf: end time of inference\n",
    "        :param t0_ann: start time of annotation\n",
    "        :param t1_ann: end time of annotation\n",
    "        :param loop_time: time taken to process the frame\n",
    "        :param bar_height: height of the stats bar\n",
    "        :param font_scale: font scale of the text\n",
    "        :param font_thickness: font thickness of the text\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = (t1_inf - t0_inf) * 1000  # Convert to milliseconds\n",
    "    \n",
    "    # Calculate annotation time\n",
    "    annotation_time = (t1_ann - t0_ann) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate max FPS\n",
    "    max_fps = 1 / loop_time if loop_time > 0 else 0\n",
    "\n",
    "    # Add text inside the rectangle\n",
    "    stats_text = (\n",
    "    f\"Inference time: {inference_time:.2f} ms | \"\n",
    "    f\"Annotation time: {annotation_time:.2f} ms | \"\n",
    "    f\"Max FPS: {max_fps:.2f}\"\n",
    "    f\"      Press 'q' to quit | Press '+' to increase confidence | Press '-' to decrease confidence\"\n",
    "    )\n",
    "        \n",
    "    # Add a rectangle at the bottom of the frame\n",
    "    h, w, _ = frame.shape  # Get frame dimensions\n",
    "    cv2.rectangle(frame, (0, h - bar_height), (w, h), (0, 0, 0), -1)  # Black rectangle\n",
    "\n",
    "    # Add text inside the rectangle\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "    cv2.putText(frame, stats_text, (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Webcam as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: 0... Success âœ… (inf frames of shape 1920x1080 at 24.00 FPS)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set confidence and IOU threshold\n",
    "conf = 0.3\n",
    "iou = 0.3\n",
    "model = model_dict[\"v8n_mask\"]\n",
    "\n",
    "# Inference on video\n",
    "results = model.predict(source=0, stream=True, conf=conf, iou=iou, verbose=False)\n",
    "\n",
    "# Create frame counter\n",
    "frame_count = 0\n",
    "\n",
    "for result in results:\n",
    "    # Extract the processed frame with predictions\n",
    "    t0 = time.time()    # Start time\n",
    "    frame = result.plot()  # Visualizes predictions on the frame\n",
    "    t1 = time.time()    # End time\n",
    "\n",
    "    # Calculate inference \n",
    "    inference_time = (t1 - t0) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate max FPS\n",
    "    max_fps = 1000 / inference_time\n",
    "\n",
    "    # Get RAM usage\n",
    "    ram_usage = get_ram_usage()\n",
    "\n",
    "    # Add text inside the rectangle\n",
    "    if frame_count % 20 == 0:\n",
    "        stats_text = (\n",
    "        f\"Inference time: {inference_time:.2f} ms | \"\n",
    "        f\"RAM usage: {ram_usage:.2f} MB | \"\n",
    "        f\"Max FPS: {max_fps:.2f}\"\n",
    "    )\n",
    "        # Reset frame count\n",
    "        frame_count = 0\n",
    "\n",
    "    # Add stats bar to the frame\n",
    "    put_stats_bar(frame=frame, bar_height=30, font_scale=0.5, font_thickness=1)\n",
    "    \n",
    "    # Display the frame in a window\n",
    "    cv2.imshow('Live Predictions', frame)\n",
    "    \n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
