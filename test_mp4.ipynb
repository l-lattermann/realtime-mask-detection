{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "v8n_person = YOLO(\"models/yolo/train_runs/yolov8n_person_100epochs/detect/train/weights/best.pt\")\n",
    "v8n_mask = YOLO(\"models/yolo/train_runs/yolov8n_mask_100epochs/train/weights/best.pt\")\n",
    "v11n_person = YOLO(\"models/yolo/train_runs/yolo11n_person_100epochs/train/weights/best.pt\")\n",
    "v11n_mask = YOLO(\"models/yolo/train_runs/yolo11n_mask_100epochs/train/weights/best.pt\")\n",
    "\n",
    "# Create model list\n",
    "model_dict = {\"v8n_person\":v8n_person, \"v8n_mask\":v8n_mask, \"v11n_person\":v11n_person, \"v11n_mask\":v11n_mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if model was loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot result images\n",
    "def matplot_image(results: list, model_name: str):\n",
    "    \"\"\"\n",
    "        Display the image using matplotlib\n",
    "        :param results: list of results from the model\n",
    "        :param model_name: name of the model\n",
    "    \"\"\"\n",
    "\n",
    "    im  = results[0].plot()\n",
    "    # Convert BGR (OpenCV format) to RGB (matplotlib format)\n",
    "    im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Add model name to the image\n",
    "    plt.title(model_name)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.axis(\"off\")  # Turn off axes for a cleaner display\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set confidence and IOU threshold\n",
    "conf = 0.3\n",
    "iou = 0.3\n",
    "\n",
    "# Test models\n",
    "for model_name, model in model_dict.items():\n",
    "    for i in range(3):\n",
    "        results = model.predict(f\"data_sets/image_data/mask_person_test/{i}.jpg\", conf=conf, iou=iou, verbose=False)\n",
    "\n",
    "        # Show results\n",
    "        #matplot_image(results, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RAM usage\n",
    "def get_ram_usage():\n",
    "    \"\"\"\n",
    "        Get the RAM usage of the system\n",
    "        :return: RAM usage in MB\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get current process\n",
    "    process = psutil.Process()\n",
    "\n",
    "    # Get memory usage in bytes and convert to MB\n",
    "    return process.memory_info().rss / (1024 ** 2)  # Resident Set Size (RSS)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put stats bar on frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put stats bar on frame\n",
    "def put_stats_bar(frame, t0_inf=0, t1_inf=0, t0_ann=0, t1_ann=0, loop_time=0, bar_height=30,font_scale=0.5, font_thickness=1):\n",
    "    \"\"\"\n",
    "        Add a stats bar at the bottom of the frame\n",
    "        :param frame: frame to add the stats bar to\n",
    "        :param t0_inf: start time of inference\n",
    "        :param t1_inf: end time of inference\n",
    "        :param t0_ann: start time of annotation\n",
    "        :param t1_ann: end time of annotation\n",
    "        :param loop_time: time taken to process the frame\n",
    "        :param bar_height: height of the stats bar\n",
    "        :param font_scale: font scale of the text\n",
    "        :param font_thickness: font thickness of the text\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate inference time\n",
    "    inference_time = (t1_inf - t0_inf) * 1000  # Convert to milliseconds\n",
    "    \n",
    "    # Calculate annotation time\n",
    "    annotation_time = (t1_ann - t0_ann) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate max FPS\n",
    "    max_fps = 1 / loop_time if loop_time > 0 else 0\n",
    "\n",
    "    # Add text inside the rectangle\n",
    "    stats_text = (\n",
    "    f\"Inference time: {inference_time:.2f} ms | \"\n",
    "    f\"Annotation time: {annotation_time:.2f} ms | \"\n",
    "    f\"Max FPS: {max_fps:.2f}\"\n",
    "    f\"      Press 'q' to quit | Press '+' to increase confidence | Press '-' to decrease confidence\"\n",
    "    )\n",
    "        \n",
    "    # Add a rectangle at the bottom of the frame\n",
    "    h, w, _ = frame.shape  # Get frame dimensions\n",
    "    cv2.rectangle(frame, (0, h - bar_height), (w, h), (0, 0, 0), -1)  # Black rectangle\n",
    "\n",
    "    # Add text inside the rectangle\n",
    "    text_color = (255, 255, 255)  # White text\n",
    "    cv2.putText(frame, stats_text, (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Webcam as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mp4 as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 10:30:36.267 Python[43226:7477691] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-03 10:30:36.267 Python[43226:7477691] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Set confidence and IOU threshold\n",
    "conf_tresh = 0.3\n",
    "iou_tresh = 0.3\n",
    "pred_framerate = 2\n",
    "model_person = v8n_person\n",
    "model_mask = v8n_mask\n",
    "\n",
    "# Initialize VideoCapture\n",
    "cap = cv2.VideoCapture(\"data_sets/video_data/zeitlupenszene-massen-von-asiaten-menschen-tragen-gesichtsschutz-in-der-prävention-für.mp4\")\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "loop_time = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % pred_framerate == 0:\n",
    "        # Perform inference for person and mask models\n",
    "        t0_inf = time.time()    # Start time\n",
    "        result_person = model_person(frame, conf=conf_tresh, iou=iou_tresh) \n",
    "        result_mask = model_mask(frame, conf=conf_tresh, iou=iou_tresh)\n",
    "        frame_count = 0 # Reset frame count\n",
    "        t1_inf = time.time()    # End time\n",
    "\n",
    "        loop_time = (time.time() - start_time)/pred_framerate\n",
    "        start_time = time.time()\n",
    "\n",
    "    t0_ann = time.time()    # Start time\n",
    "    # Extract bounding boxes, confidences, and labels from both models\n",
    "    for i in range(len(result_mask[0].boxes.cls)):\n",
    "        x1, y1, x2, y2 = map(int, result_mask[0].boxes.xyxy[i])\n",
    "        clss, conf = result_mask[0].boxes.cls[i], result_mask[0].boxes.conf[i]\n",
    "        text = f\"{model_mask.names[int(clss)]} ({conf:.2f})\"\n",
    "\n",
    "        if int(clss) == 0:\n",
    "            colorcode = (255, 165, 0)\n",
    "        elif int(clss) == 1:\n",
    "            colorcode = (0, 0, 255)\n",
    "        elif int(clss) == 2:\n",
    "            colorcode = (0,255,0)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), colorcode, 2)  # Red for model 2\n",
    "        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, colorcode, 2)\n",
    "\n",
    "    for i in range(len(result_person[0].boxes.cls)):\n",
    "        x1, y1, x2, y2 = map(int, result_person[0].boxes.xyxy[i])\n",
    "        clss, conf = result_person[0].boxes.cls[i], result_person[0].boxes.conf[i]\n",
    "        text = f\"{model_person.names[int(clss)]} ({conf:.2f})\"\n",
    "\n",
    "        colorcode = (255, 0, 0)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), colorcode, 2)  # Red for model 2\n",
    "        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, colorcode, 2)\n",
    "    \n",
    "    # Quit with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit with 'q'\n",
    "        break\n",
    "    t1_ann = time.time()    # End time\n",
    "\n",
    "    # Add stats bar to the frame\n",
    "    put_stats_bar(frame, t0_inf, t1_inf, t0_ann, t1_ann, loop_time, 30, 0.5, 1)\n",
    "\n",
    "    # Show the frame with bounding boxes\n",
    "    cv2.imshow(\"Detections\", frame)        \n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
